{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Knowledge about Gene and Protein Function with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn import manifold\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "## Harmonizome API\n",
    "from harmonizome import Harmonizome\n",
    "## Utility\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "\n",
    "## Create custom \"randfloat\" that behaves like randint but for floats\n",
    "from scipy.stats import uniform, randint\n",
    "def randfloat(start, end):\n",
    "    ''' Utility function for generating a float uniform distribution '''\n",
    "    return uniform(start, end - start)\n",
    "\n",
    "# reproducable random seed\n",
    "rng = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Given a target attribute of interest, we will use machine learning to predict genes that are strongly correlated with that target. Using the Harmonizome data query API, we download the dataset containing the target attribute as well as a number of well-populated Omics datasets for more genes and features and build a large sparse dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attribute_datasets = {{ MultiChoiceField(\n",
    "                        name='attribute_databases',\n",
    "                        label='Attribute Selection',\n",
    "                        hint='Databases to use for prediction',\n",
    "                        default=[\n",
    "                            'CCLE Cell Line Gene Expression Profiles',\n",
    "                            'ENCODE Transcription Factor Targets',\n",
    "                        ],\n",
    "                        choices=[\n",
    "                            'CCLE Cell Line Gene Expression Profiles',\n",
    "                            'ENCODE Transcription Factor Targets',\n",
    "                            'Allen Brain Atlas Adult Human Brain Tissue Gene Expression Profiles',\n",
    "                            'CHEA Transcription Factor Targets',\n",
    "                            'BioGPS Cell Line Gene Expression Profiles',\n",
    "                            'GTEx Tissue Gene Expression Profiles',\n",
    "                        ],\n",
    "                        group='Targets',\n",
    "                    ) }}\n",
    "\n",
    "\n",
    "# Download attribute datasets from Harmonizome\n",
    "df_attributes = list(Harmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))\n",
    "for name, df in zip(attribute_datasets, df_attributes):\n",
    "    df.index.name = json.loads(df.index.name)[0]\n",
    "    df.index = df.index.map(lambda s: json.loads(s)[0])\n",
    "    print('%s shape:' % (name), df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='inner', # Drop any mis-matched index\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "X = df.applymap(lambda f: 1 if f==1 else 0)\n",
    "print('Total Shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_class = \"{{ TargetClassSearchField(\n",
    "                        name='target_class',\n",
    "                        label='Class Selection',\n",
    "                        hint='Class you want to predict',\n",
    "                        default='integumentary system cancer (DOID:0060122 from DISEASES Text-mining Gene-Disease Assocation Evidence Scores)',\n",
    "                        examples=[\n",
    "                        ],\n",
    "                        group='Targets',\n",
    "                    ) }}\"\n",
    "\n",
    "# Separate target attribute and dataset\n",
    "class_name, class_type, class_dataset = re.match(\n",
    "    r'^(.+) \\((.+) from (.+)\\)$',\n",
    "    target_class,\n",
    ").groups()\n",
    "target_class_col = class_name\n",
    "\n",
    "# Download class datasets from Harmonizome\n",
    "df_class = list(Harmonizome.download_df(\n",
    "    [class_dataset],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))[0]\n",
    "df_class.columns = df_class.columns.map(lambda s: json.loads(s)[0])\n",
    "df_class.index.name = json.loads(df_class.index.name)[0]\n",
    "df_class.index = df_class.index.map(lambda s: json.loads(s)[0])\n",
    "print('%s shape:' % (class_dataset), df_class.shape)\n",
    "display(df_class.head())\n",
    "\n",
    "# Collect genes of interest\n",
    "target_genes = df_class[df_class[target_class_col] == 1].index\n",
    "print('Number of Target Genes:', len(target_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create final target array\n",
    "y = np.in1d(X.index, target_genes).astype(np.int8)\n",
    "print('Known Target Genes: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))\n",
    "\n",
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "We perform dimensionality reduction with sk.decomposition.{{ ChoiceField(name='dimensionality_reduction_algorithm', label='Dimensionality Reduction Algorithm', default='PCA', choices=['PCA', 'TruncatedSVD'], group='Algorithm') }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_dimensionality_reduction = sk.decomposition.{{ dimensionality_reduction_algorithm }}(n_components=64)\n",
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform TSNE for low dimensional visualization\n",
    "\n",
    "#tsne = sk.manifold.TSNE(n_components=2, random_state=rng)\n",
    "#X_transformed_tsne = tsne.fit_transform(X_reduced, y)\n",
    "\n",
    "# Plot results of TSNE\n",
    "plt.title('Low dimension representation')\n",
    "#plt.scatter(\n",
    "#    X_transformed_tsne[:, 0],\n",
    "#    X_transformed_tsne[:, 1],\n",
    "#    c=y,\n",
    "#)\n",
    "# Substitute for Demo\n",
    "plt.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    c=y,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "{{ DescriptionField(content='We will perform the analysis based on the selections made here.', group='Algorithm') }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensionality_reduction_algorithm = sk.decomposition.{{ dimensionality_reduction_algorithm }}\n",
    "algorithm = sk.ensemble.{{ ChoiceField(name='algorithm', label='Machine Learning Algorithm', default='RandomForestClassifier', choices=['RandomForestClassifier', 'GradientBoostingClassifier'], group='Algorithm') }}\n",
    "hyper_param_search = sk.model_selection.{{ ChoiceField(name='hyper_param_search_type', label='Hyper Parameter Search Type', default='RandomizedSearchCV', choices=['RandomizedSearchCV', 'GridSearchCV'], group='Algorithm')}}\n",
    "n_folds = {{ IntField(name='cross_validation_n_folds', label='Number of Cross-Validated Folds', default=3, min=2, max=10, group='Algorithm') }}\n",
    "primary_metric = '{{ ChoiceField(name='primary_metric', label='Primary metric', default='log_loss', choices=['log_loss'], group='Algorithm') }}'\n",
    "evaluation_metrics = {{ MultiChoiceField(name='evaluation_metrics',label='Evaluation Metrics',default=[],choices=[    'explained_variance','r2','neg_median_absolute_error','neg_mean_absolute_error','neg_mean_squared_error','neg_mean_squared_log_error','median_absolute_error','mean_absolute_error','mean_squared_error','accuracy','roc_auc','average_precision','log_loss','neg_log_loss','adjusted_rand_score','homogeneity_score','completeness_score','v_measure_score','mutual_info_score','adjusted_mutual_info_score','normalized_mutual_info_score','fowlkes_mallows_score','precision','precision_macro','precision_micro','precision_samples','precision_weighted','recall','recall_macro','recall_micro','recall_samples','recall_weighted','f1','f1_macro','f1_micro','f1_samples','f1_weighted'],group='Algorithm') }}\n",
    "cv_algorithm = sk.model_selection.StratifiedKFold\n",
    "# For quick demo--later will be selectable\n",
    "n_iter = 1\n",
    "n_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = sk.pipeline.Pipeline([\n",
    "    # Reduce dimensionality by applying TruncatedSVD\n",
    "    ('reduce_dim', dimensionality_reduction_algorithm()),\n",
    "    # Classify with gradient boosting\n",
    "    ('clf', algorithm()),\n",
    "])\n",
    "\n",
    "cv = cv_algorithm(\n",
    "    n_splits=n_folds,\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "    {% if algorithm == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "    {% elif algorithm == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    {% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "# Fit parameters\n",
    "fit_params = {\n",
    "    {% if algorithm == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "    {% endif %}\n",
    "}\n",
    "\n",
    "# Scoring parameters\n",
    "scoring_params = {k: v\n",
    "                  for k,v in metrics.scorer.SCORERS.items()\n",
    "                  if k == primary_metric or k in evaluation_metrics}\n",
    "\n",
    "# Params to pass to search\n",
    "search_params = {\n",
    "    'cv': cv,\n",
    "    'refit': primary_metric,\n",
    "    'verbose': 10,\n",
    "    'random_state': rng,\n",
    "    'scoring': {k: v\n",
    "                for k,v in scoring_params.items()\n",
    "                if k == primary_metric or k in evaluation_metrics},\n",
    "    'return_train_score': True,\n",
    "    'n_iter': n_iter,\n",
    "}\n",
    "\n",
    "search = hyper_param_search(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    **search_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate pipeline\n",
    "search.fit(X.values, y, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display training results\n",
    "if n_iter > 1:\n",
    "    for metric in [primary_metric]+evaluation_metrics:\n",
    "        df_met = pd.DataFrame.from_dict({\n",
    "            'mean_test_%s' % (metric): search.cv_results_['mean_test_%s' % (metric)],\n",
    "            'mean_train_%s' % (metric): search.cv_results_['mean_train_%s' % (metric)],\n",
    "        }).sort_values('mean_test_%s' % (metric), ascending=False)\n",
    "        df_met.plot(use_index=False)\n",
    "        plt.title('Mean %s' % (metric))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate final ROC curve\n",
    "y_probas = search.predict_proba(X.values)\n",
    "fpr, tpr, _ = sk.metrics.roc_curve(y, y_probas[:, 1])\n",
    "score = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='Final (AUC=%.3f)' % (score))\n",
    "# Annotate chart\n",
    "plt.plot([0, 1], [0, 1], '--', label='Luck')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y, search.predict(X.values))\n",
    "display(cm)\n",
    "print('\\n',\n",
    "    'True labels predicted to be true:', cm[0,0], '\\n',\n",
    "    'True labels predicted to be false:', cm[0,1], '\\n',\n",
    "    'False labels predicted to be true:', cm[1,0], '\\n',\n",
    "    'False labels predicted to be false:', cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain prediction results\n",
    "y_preds = search.predict(X)\n",
    "y_probas = search.predict_proba(X)[:, 1]\n",
    "results = pd.DataFrame(np.array([\n",
    "    y,\n",
    "    y_preds,\n",
    "    y_probas,\n",
    "]).T, columns=[\n",
    "    'Known',\n",
    "    'Predicted',\n",
    "    'Prediction Probability',\n",
    "], index=X.index)\n",
    "results[(results['Prediction Probability'] > 0.5)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
