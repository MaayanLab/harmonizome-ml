{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%nbtemplate hide\n",
    "# Prepare nbtemplate magics (use %%nbtemplate for jinja-assisted evaluation)\n",
    "# hide option tells the runtime renderer not to render this cell\n",
    "import nbtemplate\n",
    "nbtemplate.init(lambda _=globals: _())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Knowledge about Gene and Protein Function with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Imports\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "## Machine Learning\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    preprocessing,\n",
    "    decomposition,\n",
    "    ensemble,\n",
    "    model_selection,\n",
    "    pipeline,\n",
    "    metrics,\n",
    "    manifold,\n",
    "    feature_selection,\n",
    "    linear_model,\n",
    "    tree,\n",
    "    svm,\n",
    "    calibration,\n",
    ")\n",
    "## Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "## Harmonizome API\n",
    "from harmonizome import Harmonizome\n",
    "## Utility\n",
    "import re\n",
    "import json\n",
    "from functools import reduce\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "\n",
    "## Create custom \"randfloat\" that behaves like randint but for floats\n",
    "from scipy.stats import uniform, randint\n",
    "def randfloat(start, end):\n",
    "    ''' Utility function for generating a float uniform distribution '''\n",
    "    return uniform(start, end - start)\n",
    "\n",
    "# reproducable random seed\n",
    "rng = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Given a target attribute of interest, we will use machine learning to predict genes that are strongly correlated with that target. Using the Harmonizome data query API, we download the dataset containing the target attribute as well as a number of well-populated Omics datasets for more genes and features and build a large sparse dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate\n",
    "{{ SectionField(\n",
    "    title='ATTRIBUTE AND PREDICTION CLASS DATASET SELECTION',\n",
    "    subtitle='Select the datasets to use for learning and classification.',\n",
    "    group='DATASETS',\n",
    ") }}\n",
    "attribute_datasets = {{ MultiChoiceField(\n",
    "    name='attribute_datasets',\n",
    "    label='Attribute Selection (place cursor inside the box to add more datasets)',\n",
    "    hint='Databases to use for prediction',\n",
    "    description='The selected datasets will be concatenated and used to train the model.',\n",
    "    default=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "    ],\n",
    "    value=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "        'Allen Brain Atlas Adult Human Brain Tissue Gene Expression Profiles',\n",
    "        'CHEA Transcription Factor Targets',\n",
    "        'BioGPS Cell Line Gene Expression Profiles',\n",
    "        'GTEx Tissue Gene Expression Profiles',\n",
    "    ],\n",
    "    choices=[\n",
    "        'CCLE Cell Line Gene Expression Profiles',\n",
    "        'ENCODE Transcription Factor Targets',\n",
    "        'Allen Brain Atlas Adult Human Brain Tissue Gene Expression Profiles',\n",
    "        'CHEA Transcription Factor Targets',\n",
    "        'BioGPS Cell Line Gene Expression Profiles',\n",
    "        'GTEx Tissue Gene Expression Profiles',\n",
    "    ],\n",
    "    group='DATASETS',\n",
    ") }}\n",
    "target_class = \"{{ TargetClassSearchField(\n",
    "    name='target_class',\n",
    "    label='Class Selection',\n",
    "    hint='Class you want to predict',\n",
    "    default='integumentary system cancer (DOID:0060122 from DISEASES Text-mining Gene-Disease Assocation Evidence Scores)',\n",
    "    value='female breast cancer (DOID:0050671 from DISEASES Text-mining Gene-Disease Assocation Evidence Scores)',\n",
    "    hints=[\n",
    "        'cancer',\n",
    "        'lung',\n",
    "        'heart',\n",
    "        'tumor',\n",
    "    ],\n",
    "    group='DATASETS',\n",
    ") }}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Omics datasets are downloaded and joined on the Gene producing a large association matrix. Only association is preserved in order to create a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download attribute datasets from Harmonizome\n",
    "df_attributes = list(Harmonizome.download_df(\n",
    "    [dataset\n",
    "     for dataset in attribute_datasets],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))\n",
    "for name, df in zip(attribute_datasets, df_attributes):\n",
    "    df.index.name = json.loads(df.index.name)[0]\n",
    "    df.index = df.index.map(lambda s: json.loads(s)[0])\n",
    "    print('%s shape:' % (name), df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "# Assemble all attribute datasets\n",
    "if len(df_attributes) > 1:\n",
    "    # Obtain merged dataframe with omics and target data\n",
    "    df = reduce(\n",
    "        lambda a, b: pd.merge( # Merge two dataframes item by item\n",
    "            a, # left\n",
    "            b, # right\n",
    "            # Items with the same left and right index are merged\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='outer', # Keep mis-matched index\n",
    "        ),\n",
    "        df_attributes,\n",
    "    )\n",
    "else:\n",
    "    df = df_attributes[0]\n",
    "\n",
    "X = df.applymap(lambda f: 1 if f!=1 else 0)\n",
    "print('Total Shape:', X.shape)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the dataset containtaining the target class name and assemble an list of genes associated with that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target attribute and dataset\n",
    "class_name, class_type, class_dataset = re.match(\n",
    "    r'^(.+) \\((.+) from (.+)\\)$',\n",
    "    target_class,\n",
    ").groups()\n",
    "target_class_col = class_name\n",
    "\n",
    "# Download class datasets from Harmonizome\n",
    "df_class = list(Harmonizome.download_df(\n",
    "    [class_dataset],\n",
    "    ['gene_attribute_matrix.txt.gz'],\n",
    "))[0]\n",
    "df_class.columns = df_class.columns.map(lambda s: json.loads(s)[0])\n",
    "df_class.index.name = json.loads(df_class.index.name)[0]\n",
    "df_class.index = df_class.index.map(lambda s: json.loads(s)[0])\n",
    "print('%s shape:' % (class_dataset), df_class.shape)\n",
    "display(df_class.head())\n",
    "\n",
    "# Collect genes of interest\n",
    "target_genes = df_class[df_class[target_class_col] == 1].index\n",
    "print('Number of Target Genes:', len(target_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a target array containing 1 if the gene is associated and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final target array\n",
    "y = np.in1d(X.index, target_genes).astype(np.int8)\n",
    "print('Known Target Genes: %d (%0.3f %%)' % (y.sum(), 100*y.sum()/len(y)))\n",
    "\n",
    "# Output data shapes\n",
    "print('Input shape:', X.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%nbtemplate\n",
    "## Dimensionality Reduction\n",
    "\n",
    "We reduce the dimensionality of our omics feature space with {{ clf_dimensionality_reduction.value }}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate\n",
    "{{ SectionField(\n",
    "    title='SETTINGS',\n",
    "    subtitle='From here you can select the various available Machine Learning algorithms, their unique settings, and the methods to use to evaluate the classifier.',\n",
    "    group='SETTINGS',\n",
    ") }}\n",
    "clf_dimensionality_reduction = {{ ChoiceField(\n",
    "    name='clf_dimensionality_reduction',\n",
    "    label='Dimensionality Reduction Algorithm',\n",
    "    description='A dimensionality reduction algorithm should be selected to improve the quality of the classifier.',\n",
    "    default='PCA',\n",
    "    choices={\n",
    "        'PCA': 'sk.decomposition.PCA(n_components=64)',\n",
    "        'TruncatedSVD': 'sk.decomposition.TruncatedSVD(n_components=64)',\n",
    "        'IncrementalPCA': 'sk.decomposition.IncrementalPCA(n_components=64)',\n",
    "        'ICA': 'sk.decomposition.FastICA(n_components=64)',\n",
    "        'SparsePCA': 'sk.decomposition.SparsePCA(n_components=64)',\n",
    "    },\n",
    "    group='SETTINGS'\n",
    ") }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = clf_dimensionality_reduction.fit_transform(X.values)\n",
    "if hasattr(clf_dimensionality_reduction, 'explained_variance_'):\n",
    "    print('Explained variance:', np.sum(clf_dimensionality_reduction.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate hide\n",
    "{% if tsne %}\n",
    "# Perform TSNE for low dimensional visualization\n",
    "tsne = sk.manifold.TSNE(n_components=2, random_state=rng)\n",
    "X_transformed = tsne.fit_transform(X_reduced, y)\n",
    "plt.scatter(\n",
    "   X_transformed_tsne[:, 0],\n",
    "   X_transformed_tsne[:, 1],\n",
    "   c=y,\n",
    ")\n",
    "{% else %}\n",
    "plt.title('Low dimension representation')\n",
    "plt.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    c=y,\n",
    ")\n",
    "plt.show()\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%nbtemplate\n",
    "## Machine Learning\n",
    "{#\n",
    "We apply a {{ hyper_param_search.value }} search for the hyper parameters of a sklearn pipeline with a dimensionality reduction step of {{ clf_dimensionality_reduction.value }} and a {{ algorithm.value }} classifier using {{ cross_validation_n_folds.value }}-fold repeated stratified cross-validation, optimizing {{ primary_metric.value }}{% if evaluation_metrics.value %} and computing {{ evaluation_metrics.value.join(', ') }}{% endif %}.\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate\n",
    "feature_selection = {{ ChoiceField(\n",
    "    name='feature_selection',\n",
    "    label='Machine Learning Feature Selection',\n",
    "    default='SelectFromLinearSVC',\n",
    "    choices={\n",
    "        'SelectFromLinearSVC': 'sk.feature_selection.SelectFromModel(sk.svm.LinearSVC(loss=\"squared_hinge\", penalty=\"l1\", dual=False))',\n",
    "        'SelectFromExtraTrees': 'sk.feature_selection.SelectFromModel(sk.tree.ExtraTreesClassifier())',\n",
    "        'SelectKBest': 'sk.feature_selection.SelectKBest(\"f_classif\")',\n",
    "        'SelectKBestChi2': 'sk.feature_selection.SelectKBest(\"chi2\")',\n",
    "        'SelectKBestMultiInfo': 'sk.feature_selection.SelectKBest(\"mutual_info_classif\")',\n",
    "    },\n",
    "    group='SETTINGS'\n",
    ") }}\n",
    "cv_algorithm = {{ ChoiceField(\n",
    "    name='cv_algorithm',\n",
    "    label='Cross Validation Algorithm',\n",
    "    default='StratifiedKFold',\n",
    "    choices={\n",
    "        'KFold': 'sk.model_selection.KFold',\n",
    "        'GroupKFold': 'sk.model_selection.GroupKFold',\n",
    "        'RepeatedKFold': 'sk.model_selection.RepeatedKFold',\n",
    "        'StratifiedKFold': 'sk.model_selection.StratifiedKFold',\n",
    "        'RepeatedStratifiedKFold': 'sk.model_selection.RepeatedStratifiedKFold',\n",
    "    },\n",
    "    group='SETTINGS',\n",
    ") }}\n",
    "algorithm = {{ ChoiceField(\n",
    "    name='algorithm',\n",
    "    label='Machine Learning Algorithm',\n",
    "    default='RandomForestClassifier',\n",
    "    description='A machine learning algorithm should be selected to construct the predictive model.',\n",
    "    choices={\n",
    "        'GradientBoostingClassifier': 'sk.ensemble.GradientBoostingClassifier()',\n",
    "        'RandomForestClassifier': 'sk.ensemble.RandomForestClassifier()',\n",
    "        'AdaBoostClassifier': 'sk.ensemble.AdaBoostClassifier()',\n",
    "        'ExtraTreesClassifier': 'sk.tree.ExtraTreesClassifier()',\n",
    "        'DecisionTreeClassifier': 'sk.tree.DecisionTreeClassifier()',\n",
    "        'KNeighborsClassifier': 'sk.neighbors.KNeighborsClassifier()',\n",
    "        'RadiusNeighborsClassifier': 'sk.neighbors.RadiusNeighborsClassifier()',\n",
    "        'MLPClassifier': 'sk.neural_network.MLPClassifier()',\n",
    "        'OneClassSVM': 'sk.svm.OneClassSVM()',\n",
    "    },\n",
    "    group='SETTINGS'\n",
    ") }}\n",
    "hyper_param_search = {{ ChoiceField(\n",
    "    name='hyper_param_search',\n",
    "    label='Hyper Parameter Search Type',\n",
    "    default='RandomizedSearchCV',\n",
    "    description='Hyper parameter searching is used to automatically select the best parameters (using the primary metric as the criteria).',\n",
    "    choices={\n",
    "        'RandomizedSearchCV': 'sk.model_selection.RandomizedSearchCV',\n",
    "        'GridSearchCV': 'sk.model_selection.GridSearchCV',\n",
    "    },\n",
    "    group='SETTINGS'\n",
    ") }}\n",
    "cross_validation_n_folds = {{ IntField(\n",
    "    name='cross_validation_n_folds',\n",
    "    label='Cross-Validated Folds',\n",
    "    description='Cross validation is employed as a strategy to train the model on data that the model has not seen before, more folds will ensure that the model is generalizing well.',\n",
    "    default=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    group='SETTINGS'\n",
    ") }}\n",
    "primary_metric = \"{{ ChoiceField(\n",
    "    name='primary_metric',\n",
    "    label='Primary Evaluation Metric',\n",
    "    default='roc_auc',\n",
    "    description='The primary evaluation metric is used for deciding how we assess the performance of our model.',\n",
    "    choices=[\n",
    "        'explained_variance',\n",
    "        'r2',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'median_absolute_error',\n",
    "        'mean_absolute_error',\n",
    "        'mean_squared_error',\n",
    "        'accuracy',\n",
    "        'roc_auc',\n",
    "        'average_precision',\n",
    "        'log_loss',\n",
    "        'neg_log_loss',\n",
    "        'adjusted_rand_score',\n",
    "        'homogeneity_score',\n",
    "        'completeness_score',\n",
    "        'v_measure_score',\n",
    "        'mutual_info_score',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'normalized_mutual_info_score',\n",
    "        'fowlkes_mallows_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_samples',\n",
    "        'precision_weighted',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_samples',\n",
    "        'recall_weighted',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_samples',\n",
    "        'f1_weighted'\n",
    "    ],\n",
    "    group='SETTINGS'\n",
    ") }}\"\n",
    "evaluation_metrics = {{ MultiChoiceField(\n",
    "    name='evaluation_metrics',\n",
    "    label='Evaluation Metrics',\n",
    "    default=[],\n",
    "    description='Additional evaluation metrics can be specified, these metrics will also be reported for all models trained.',\n",
    "    choices=[\n",
    "        'explained_variance',\n",
    "        'r2',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_mean_squared_error',\n",
    "        'neg_mean_squared_log_error',\n",
    "        'median_absolute_error',\n",
    "        'mean_absolute_error',\n",
    "        'mean_squared_error',\n",
    "        'accuracy',\n",
    "        'roc_auc',\n",
    "        'average_precision',\n",
    "        'log_loss',\n",
    "        'neg_log_loss',\n",
    "        'adjusted_rand_score',\n",
    "        'homogeneity_score',\n",
    "        'completeness_score',\n",
    "        'v_measure_score',\n",
    "        'mutual_info_score',\n",
    "        'adjusted_mutual_info_score',\n",
    "        'normalized_mutual_info_score',\n",
    "        'fowlkes_mallows_score',\n",
    "        'precision',\n",
    "        'precision_macro',\n",
    "        'precision_micro',\n",
    "        'precision_samples',\n",
    "        'precision_weighted',\n",
    "        'recall',\n",
    "        'recall_macro',\n",
    "        'recall_micro',\n",
    "        'recall_samples',\n",
    "        'recall_weighted',\n",
    "        'f1',\n",
    "        'f1_macro',\n",
    "        'f1_micro',\n",
    "        'f1_samples',\n",
    "        'f1_weighted'\n",
    "    ],\n",
    "    group='SETTINGS',\n",
    ") }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "## Early stopping function\n",
    "def early_stopping(n_rounds, tol=0.001):\n",
    "    def early_stopping_func(i, self, local):\n",
    "        rounds = getattr(self, '__rounds', 0)\n",
    "        last = getattr(self, '__last', None)\n",
    "        current = self.train_score_[i]\n",
    "        if last and current and abs(current - last) < tol:\n",
    "            rounds += 1\n",
    "            if rounds > n_rounds:\n",
    "                return True\n",
    "        else:\n",
    "            rounds = 0\n",
    "        setattr(self, '__last', current)\n",
    "        setattr(self, '__rounds', rounds)\n",
    "        return False\n",
    "    return early_stopping_func\n",
    "{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate hide\n",
    "{#\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': randint(2, 1024),\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__loss': ['deviance', 'exponential'],\n",
    "    'clf__learning_rate': randfloat(0.001, 1.),\n",
    "    'clf__subsample': randfloat(0.01, 1.),\n",
    "{% elif algorithm.value == 'RandomForestClassifier' %}\n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "{% endif %}\n",
    "    'clf__n_estimators': randint(10, 200),\n",
    "    'clf__max_depth': randint(20, 50),\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__min_impurity_decrease': randfloat(0., 0.2),\n",
    "    'clf__min_weight_fraction_leaf': randfloat(0., 0.5),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "{% if algorithm.value == 'GradientBoostingClassifier' %}\n",
    "    'clf__monitor': early_stopping(5),\n",
    "{% endif %}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv_algorithm(\n",
    "    n_splits=cross_validation_n_folds,\n",
    "    shuffle=True,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "model = sk.calibration.CalibratedClassifierCV(\n",
    "    sk.pipeline.Pipeline([\n",
    "        ('reduce_dim', clf_dimensionality_reduction),\n",
    "        ('feature_selection', feature_selection),\n",
    "        ('clf', algorithm),\n",
    "    ]),\n",
    "    cv=cv,\n",
    ")\n",
    "\n",
    "# Scoring parameters\n",
    "scoring_params = {k: v\n",
    "                  for k,v in metrics.scorer.SCORERS.items()\n",
    "                  if k == primary_metric or k in evaluation_metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows illustrates the cross-validated performance of the model. Low fold variance and high AUC is desired in a well-generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X.values, y)):\n",
    "    model.fit(X.values[train], y[train])\n",
    "    y_proba = model.predict_proba(X.values[test]) # Probability prediction will be True\n",
    "    fpr, tpr, _ = sk.metrics.roc_curve(y[test], y_proba[:, 1])\n",
    "    tprs.append(sp.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = sk.metrics.auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, alpha=0.4, label='ROC Fold %d (AUC=%0.3f)' % (fold, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--', label='Luck')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (mean_auc - 0.5)/std_auc\n",
    "cl = sp.stats.norm.cdf(z) * 100\n",
    "ci = sp.stats.norm.interval(0.95, loc=mean_auc, scale=std_auc)\n",
    "print('Confidence interval (95%)', ci)\n",
    "print(\"We are %0.3f %% confident the model's results are not just chance.\" % (cl))\n",
    "if cl > 95:\n",
    "    print('This is statistically significant. These results can be trusted.')\n",
    "else:\n",
    "    print('This is not statistically significant. These results should not be trusted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time as we are evaluating n_iter different models n_splits different times each computing all the metrics on `product(X.shape)` data points--not to mention the size of each model dictated by the range of parameters specified in the params dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y, model.predict(X.values))\n",
    "display(cm)\n",
    "print('\\n',\n",
    "    'True labels predicted to be true:', cm[0,0], '\\n',\n",
    "    'True labels predicted to be false:', cm[0,1], '\\n',\n",
    "    'False labels predicted to be true:', cm[1,0], '\\n',\n",
    "    'False labels predicted to be false:', cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain prediction results\n",
    "y_preds = model.predict(X)\n",
    "y_probas = model.predict_proba(X)[:, 1]\n",
    "results = pd.DataFrame(np.array([\n",
    "    y,\n",
    "    y_preds,\n",
    "    y_probas,\n",
    "]).T, columns=[\n",
    "    'Known',\n",
    "    'Predicted',\n",
    "    'Prediction Probability',\n",
    "], index=X.index)\n",
    "results[(results['Prediction Probability'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nbtemplate hide\n",
    "{{ SectionField(\n",
    "    title='LAUNCH',\n",
    "    subtitle='Loading...',\n",
    "    group='LAUNCH',\n",
    ") }}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
